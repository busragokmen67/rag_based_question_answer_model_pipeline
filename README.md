# rag_based_question_answer_model_pipeline

ğŸ“Œ Features

ğŸ—‚ Load and clean .txt documents

ğŸ“ Auto-chunk based on the smallest document

ğŸ§  Embed using sentence-transformers (MiniLM)

ğŸ“ˆ Retrieve top-k most relevant chunks via cosine similarity

ğŸ’¬ Answer questions using falcon-rw-1b (local, CPU-friendly)

âœ… Fully offline, no OpenAI API required
